{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../assets/images/autoencoder.png\">\n",
    "\n",
    "\n",
    "In CNN's we have learnt that through a series of layers we are transforming(reducing) the input image across X & Y dimensions but much greater in depth. Along the way we are discarding the spatial information from the input image and isolating the high level informationabout its content, and this can be seen as data compression technique wherein image is compressed to its feature vectors which is basically a feature map and this is what makes up something called autoencoder.\n",
    "\n",
    "\n",
    "<img src=\"../../assets/images/datacompression.png\">\n",
    "\n",
    "An autoencoder has 2 components:\n",
    "* Encoder that compresses the data\n",
    "* Decoder that reconstructs the data from the compressed representation\n",
    "\n",
    "\n",
    "<img src=\"../../assets/images/enc_dec.png\">\n",
    "\n",
    "As you might have guessed the autoencoder can be used for data compression wherein the dimensionality of the actual data is reduced to the minimum representable form. Now we have data compression techniques such as Jpeg compression but here the autoencoder will learn the most efficient parameters to achive the data compression.\n",
    "\n",
    "Autoencoders have shown affective de-noising techniques \n",
    "\n",
    "\n",
    "<img src=\"../../assets/images/denoising.png\">\n",
    "\n",
    "Now here both the encoder and decoder are made up of neural networks and the whole network is trained by minimizing the difference between the input and the output and here the middle layer will be the compressed representation wherein the output can be reconstructed.\n",
    "\n",
    "The main aspect of the autoencoder is in its ability to compress the image while maintaining the main contents of the image and later we can use this compressed representaion to generate something else which is why this has a application in generative modelling.\n",
    "\n",
    "#### <u>Linear Autoencoder practical </u>\n",
    "[Linear Autoencoder](../../assets/notebooks/LinearAutoencoder.ipynb)\n",
    "\n",
    "So far so good. Till here we have learnt about how to construct a simple linear layer autoencoder but iin actual practice to get the better accuracy we will look at convolutional autoencoder. Here Encoder network will be a series of convolution and maxpooling layers which downsamples the image. But in decoder network we need to use something called De-convolutional network which will do the upsampling part and this is done using transpose convolution.\n",
    "\n",
    "Transpose convolution\n",
    "<img src='https://miro.medium.com/max/1400/1*kOThnLR8Fge_AJcHrkR3dg.gif'>\n",
    "In the above gif an invisible (3x3) kernel is applied to (4x4) image to get (6x6) output image. Here the kernel weights are to be learned same as in case of convolutional network.\n",
    "\n",
    "\n",
    "#### <u>Convolutional Autoencoder practical </u>\n",
    "[Convolutional Autoencoder](../../assets/notebooks/Convolutional_Autoencoder.ipynb)\n",
    "\n",
    "#### <u>Convolutional Autoencoder with upsampling practical </u>\n",
    "[Convolutional Autoencoder with upsampling](../../assets/notebooks/Upsampling_conv_autoencoder.ipynb)\n",
    "\n",
    "#### <u>Denoising autorncoder </u>\n",
    "[Denoising autoencoder](../../assets/notebooks/Denoising_Autoencoder.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
